{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings( 'ignore' )\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "\n",
    "from contextlib import redirect_stdout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # supress tensorflow warnings\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import All_UT_Models\n",
    "import UT_Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters for this model\n",
    "\n",
    "MAX_LEN = 131\n",
    "EMBED_SIZE = 768\n",
    "BERT_TRAINABLE = True\n",
    "\n",
    "DRPT = 0.4\n",
    "FC_WEIGHTS_INIT = 'he_uniform'\n",
    "FC_ACT = 'elu'\n",
    "LR_RATE = 6e-5\n",
    "OPTIMIZER = 'adam'\n",
    "\n",
    "BATCH = 32\n",
    "NEPOCHS = 20\n",
    "PATIENCE = 4\n",
    "DECAY = True\n",
    "DECAY_RATE = 0.3\n",
    "DECAY_AFTER = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'hfFineTuneMT5'\n",
    "\n",
    "modelpath = './Saved Models/' + modelname + '/'\n",
    "modelresults = './Model Results'\n",
    "modelsummaries = './Model - Summaries-Figures'\n",
    "\n",
    "DIRECTORIES_TO_BE_CREATED = [ modelpath, modelresults, modelsummaries ]\n",
    "for directory in DIRECTORIES_TO_BE_CREATED:\n",
    "    if not os.path.exists( directory ):\n",
    "        os.makedirs( directory )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Embeddings/huggingface/google/mt5-base/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertmodelname = 'google/mt5-base'\n",
    "\n",
    "hfcachedir = './Embeddings/huggingface/{}/'.format( bertmodelname )\n",
    "hfcachedir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hms_string( sec_elapsed ):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{} hrs {:>02} mins {:>05.2f} secs\".format( h, m, s )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72771, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheets = [ pd.read_excel( 'RUT_UT_Comments.xlsx', 'Sheet1' ), pd.read_excel( 'RUT_UT_Comments.xlsx', 'Sheet2' ) ]\n",
    "df = pd.concat( sheets )\n",
    "df.reset_index( drop=True, inplace=True )\n",
    "\n",
    "df.Urdu = df.Urdu.astype( 'str' )\n",
    "df.Urdu = df.Urdu.apply( UT_Utils.urdu_preprocessing )\n",
    "\n",
    "df.dropna( inplace=True )\n",
    "df.reset_index( drop=True, inplace=True )\n",
    "\n",
    "del sheets\n",
    "gc.collect()\n",
    "\n",
    "xcolumn = 'Urdu'\n",
    "ycolumn = 'Toxic'\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def FineTuneBertWithDenseLayer(\n",
    "    bert_model, max_len=128, drpt=0.1, fc_weights_init='', fc_act='', optimizer='' ):\n",
    "    \n",
    "    input_ids_in = tf.keras.layers.Input( shape=( max_len, ), dtype='int32' )\n",
    "    input_masks_in = tf.keras.layers.Input( shape=( max_len, ), dtype='int32' )\n",
    "    \n",
    "    embedding_layer = bert_model( input_ids_in, attention_mask=input_masks_in )\n",
    "    \n",
    "    hidden_state = embedding_layer.last_hidden_state\n",
    "    pooler = hidden_state[:, 0]\n",
    "    \n",
    "    d = Dropout( drpt )( pooler )\n",
    "    d = Dense( 768, activation=fc_act, kernel_initializer=fc_weights_init )( d )\n",
    "    outp = Dense( 1, activation='sigmoid' )( d )\n",
    "    \n",
    "    model = Model( inputs=[ input_ids_in, input_masks_in ], outputs=outp )\n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, MT5Config, TFMT5EncoderModel\n",
    "from transformers import utils\n",
    "utils.logging.set_verbosity( 40 ) # supress huggingface warnings\n",
    "os.environ[ \"TOKENIZERS_PARALLELISM\" ] = \"false\" # disabling tokenizers parallelism to avoid deadlocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize bert tokenizer\n",
    "BERT_TOKENIZER = T5Tokenizer.from_pretrained( bertmodelname )\n",
    "\n",
    "# define function to tokenize input Urdu comments using bert tokenizer\n",
    "def get_tokens_and_masks( bert_tokenizer, sentences, max_length=128, padding='max_length' ):\n",
    "    encoded_input = bert_tokenizer(\n",
    "        sentences,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        padding=padding,\n",
    "        truncation=True,\n",
    "        return_attention_mask = True\n",
    "    )\n",
    "    return np.array( encoded_input[ 'input_ids' ] ), np.array( encoded_input[ 'attention_mask' ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MT5Config {\n",
       "  \"_name_or_path\": \"/home/patrick/hugging_face/t5/mt5-base\",\n",
       "  \"architectures\": [\n",
       "    \"MT5ForConditionalGeneration\"\n",
       "  ],\n",
       "  \"d_ff\": 2048,\n",
       "  \"d_kv\": 64,\n",
       "  \"d_model\": 768,\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"dense_act_fn\": \"gelu_new\",\n",
       "  \"dropout_rate\": 0.1,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"feed_forward_proj\": \"gated-gelu\",\n",
       "  \"initializer_factor\": 1.0,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"is_gated_act\": true,\n",
       "  \"layer_norm_epsilon\": 1e-06,\n",
       "  \"model_type\": \"mt5\",\n",
       "  \"num_decoder_layers\": 12,\n",
       "  \"num_heads\": 12,\n",
       "  \"num_layers\": 12,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"relative_attention_max_distance\": 128,\n",
       "  \"relative_attention_num_buckets\": 32,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"tokenizer_class\": \"T5Tokenizer\",\n",
       "  \"transformers_version\": \"4.20.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 250112\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT_CONFIG = MT5Config.from_pretrained( bertmodelname )\n",
    "BERT_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold( n_splits=5, random_state=0, shuffle=True )\n",
    "print(skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local System Time: 11:32 PM\n",
      "Epoch: 001 --LR: 6e-05 --MaxValF1: 0.6864216 --CurValF1: 0.6864216 --Patience: 01 --F1 improved: 0.6864216\n",
      "Epoch: 002 --LR: 6e-05 --MaxValF1: 0.8027496 --CurValF1: 0.8027496 --Patience: 01 --F1 improved: 0.8027496\n",
      "Epoch: 003 --LR: 6e-05 --MaxValF1: 0.8479173 --CurValF1: 0.8479173 --Patience: 01 --F1 improved: 0.8479173\n",
      "Epoch: 004 --LR: 6e-05 --MaxValF1: 0.8511489 --CurValF1: 0.8511489 --Patience: 01 --F1 improved: 0.8511489\n",
      "Epoch: 005 --LR: 6e-05 --MaxValF1: 0.8768043 --CurValF1: 0.8768043 --Patience: 01 --F1 improved: 0.8768043\n",
      "Epoch: 006 --LR: 6e-05 --MaxValF1: 0.8833561 --CurValF1: 0.8833561 --Patience: 01 --F1 improved: 0.8833561\n",
      "Epoch: 007 --LR: 6e-05 --MaxValF1: 0.8899868 --CurValF1: 0.8899868 --Patience: 01 --F1 improved: 0.8899868\n",
      "Epoch: 008 --LR: 6e-05 --MaxValF1: 0.8940217 --CurValF1: 0.8940217 --Patience: 01 --F1 improved: 0.8940217\n",
      "Epoch: 009 --LR: 6e-05 --MaxValF1: 0.8940217 --CurValF1: 0.8886019 --Patience: 01\n",
      "Epoch: 010 --LR: 2e-05 --MaxValF1: 0.8958611 --CurValF1: 0.8958611 --Patience: 02 --F1 improved: 0.8958611\n",
      "Epoch: 011 --LR: 2e-05 --MaxValF1: 0.8982155 --CurValF1: 0.8982155 --Patience: 01 --F1 improved: 0.8982155\n",
      "Epoch: 012 --LR: 2e-05 --MaxValF1: 0.9004992 --CurValF1: 0.9004992 --Patience: 01 --F1 improved: 0.9004992\n",
      "Epoch: 013 --LR: 2e-05 --MaxValF1: 0.9004992 --CurValF1: 0.8987426 --Patience: 01\n",
      "Epoch: 014 --LR: 5e-06 --MaxValF1: 0.9004992 --CurValF1: 0.8981082 --Patience: 02\n",
      "Epoch: 015 --LR: 2e-06 --MaxValF1: 0.9004992 --CurValF1: 0.8971276 --Patience: 03\n",
      "Epoch: 016 --LR: 5e-07 --MaxValF1: 0.9004992 --CurValF1: 0.8971466 --Patience: 04\n",
      "Training stopped due to the patience parameter. --Patience: 04\n",
      "Fold: 01 out of 05 completed.\n",
      "Local System Time: 02:19 AM\n",
      "Epoch: 001 --LR: 6e-05 --MaxValF1: 0.6913501 --CurValF1: 0.6913501 --Patience: 01 --F1 improved: 0.6913501\n",
      "Epoch: 002 --LR: 6e-05 --MaxValF1: 0.7411444 --CurValF1: 0.7411444 --Patience: 01 --F1 improved: 0.7411444\n",
      "Epoch: 003 --LR: 6e-05 --MaxValF1: 0.8495922 --CurValF1: 0.8495922 --Patience: 01 --F1 improved: 0.8495922\n",
      "Epoch: 004 --LR: 6e-05 --MaxValF1: 0.8695364 --CurValF1: 0.8695364 --Patience: 01 --F1 improved: 0.8695364\n",
      "Epoch: 005 --LR: 6e-05 --MaxValF1: 0.8794186 --CurValF1: 0.8794186 --Patience: 01 --F1 improved: 0.8794186\n",
      "Epoch: 006 --LR: 6e-05 --MaxValF1: 0.8937438 --CurValF1: 0.8937438 --Patience: 01 --F1 improved: 0.8937438\n",
      "Epoch: 007 --LR: 6e-05 --MaxValF1: 0.8965517 --CurValF1: 0.8965517 --Patience: 01 --F1 improved: 0.8965517\n",
      "Epoch: 008 --LR: 6e-05 --MaxValF1: 0.9006273 --CurValF1: 0.9006273 --Patience: 01 --F1 improved: 0.9006273\n",
      "Epoch: 009 --LR: 6e-05 --MaxValF1: 0.9006273 --CurValF1: 0.8993377 --Patience: 01\n",
      "Epoch: 010 --LR: 2e-05 --MaxValF1: 0.9006273 --CurValF1: 0.8985409 --Patience: 02\n",
      "Epoch: 011 --LR: 5e-06 --MaxValF1: 0.9013158 --CurValF1: 0.9013158 --Patience: 03 --F1 improved: 0.9013158\n",
      "Epoch: 012 --LR: 5e-06 --MaxValF1: 0.9026081 --CurValF1: 0.9026081 --Patience: 01 --F1 improved: 0.9026081\n",
      "Epoch: 013 --LR: 5e-06 --MaxValF1: 0.9026081 --CurValF1: 0.9016835 --Patience: 01\n",
      "Epoch: 014 --LR: 2e-06 --MaxValF1: 0.9026081 --CurValF1: 0.9019211 --Patience: 02\n",
      "Epoch: 015 --LR: 5e-07 --MaxValF1: 0.9026081 --CurValF1: 0.9022252 --Patience: 03\n",
      "Epoch: 016 --LR: 1e-07 --MaxValF1: 0.9026081 --CurValF1: 0.9018303 --Patience: 04\n",
      "Training stopped due to the patience parameter. --Patience: 04\n",
      "Fold: 02 out of 05 completed.\n",
      "Local System Time: 05:07 AM\n",
      "Epoch: 001 --LR: 6e-05 --MaxValF1: 0.6181198 --CurValF1: 0.6181198 --Patience: 01 --F1 improved: 0.6181198\n",
      "Epoch: 002 --LR: 6e-05 --MaxValF1: 0.7038983 --CurValF1: 0.7038983 --Patience: 01 --F1 improved: 0.7038983\n",
      "Epoch: 003 --LR: 6e-05 --MaxValF1: 0.7915633 --CurValF1: 0.7915633 --Patience: 01 --F1 improved: 0.7915633\n",
      "Epoch: 004 --LR: 6e-05 --MaxValF1: 0.8344850 --CurValF1: 0.8344850 --Patience: 01 --F1 improved: 0.8344850\n",
      "Epoch: 005 --LR: 6e-05 --MaxValF1: 0.8600728 --CurValF1: 0.8600728 --Patience: 01 --F1 improved: 0.8600728\n",
      "Epoch: 006 --LR: 6e-05 --MaxValF1: 0.8696228 --CurValF1: 0.8696228 --Patience: 01 --F1 improved: 0.8696228\n",
      "Epoch: 007 --LR: 6e-05 --MaxValF1: 0.8803245 --CurValF1: 0.8803245 --Patience: 01 --F1 improved: 0.8803245\n",
      "Epoch: 008 --LR: 6e-05 --MaxValF1: 0.8877688 --CurValF1: 0.8877688 --Patience: 01 --F1 improved: 0.8877688\n",
      "Epoch: 009 --LR: 6e-05 --MaxValF1: 0.8935310 --CurValF1: 0.8935310 --Patience: 01 --F1 improved: 0.8935310\n",
      "Epoch: 010 --LR: 6e-05 --MaxValF1: 0.8973081 --CurValF1: 0.8973081 --Patience: 01 --F1 improved: 0.8973081\n",
      "Epoch: 011 --LR: 6e-05 --MaxValF1: 0.8976898 --CurValF1: 0.8976898 --Patience: 01 --F1 improved: 0.8976898\n",
      "Epoch: 012 --LR: 6e-05 --MaxValF1: 0.8994744 --CurValF1: 0.8994744 --Patience: 01 --F1 improved: 0.8994744\n",
      "Epoch: 013 --LR: 6e-05 --MaxValF1: 0.8994744 --CurValF1: 0.8991681 --Patience: 01\n",
      "Epoch: 014 --LR: 2e-05 --MaxValF1: 0.9002981 --CurValF1: 0.9002981 --Patience: 02 --F1 improved: 0.9002981\n",
      "Epoch: 015 --LR: 2e-05 --MaxValF1: 0.9002981 --CurValF1: 0.8983107 --Patience: 01\n",
      "Epoch: 016 --LR: 5e-06 --MaxValF1: 0.9002981 --CurValF1: 0.8997326 --Patience: 02\n",
      "Epoch: 017 --LR: 2e-06 --MaxValF1: 0.9002981 --CurValF1: 0.8997326 --Patience: 03\n",
      "Epoch: 018 --LR: 5e-07 --MaxValF1: 0.9002981 --CurValF1: 0.8996678 --Patience: 04\n",
      "Training stopped due to the patience parameter. --Patience: 04\n",
      "Fold: 03 out of 05 completed.\n",
      "Local System Time: 08:16 AM\n",
      "Epoch: 001 --LR: 6e-05 --MaxValF1: 0.7291482 --CurValF1: 0.7291482 --Patience: 01 --F1 improved: 0.7291482\n",
      "Epoch: 002 --LR: 6e-05 --MaxValF1: 0.8576170 --CurValF1: 0.8576170 --Patience: 01 --F1 improved: 0.8576170\n",
      "Epoch: 003 --LR: 6e-05 --MaxValF1: 0.8697772 --CurValF1: 0.8697772 --Patience: 01 --F1 improved: 0.8697772\n",
      "Epoch: 004 --LR: 6e-05 --MaxValF1: 0.8803671 --CurValF1: 0.8803671 --Patience: 01 --F1 improved: 0.8803671\n",
      "Epoch: 005 --LR: 6e-05 --MaxValF1: 0.8872823 --CurValF1: 0.8872823 --Patience: 01 --F1 improved: 0.8872823\n",
      "Epoch: 006 --LR: 6e-05 --MaxValF1: 0.8930818 --CurValF1: 0.8930818 --Patience: 01 --F1 improved: 0.8930818\n",
      "Epoch: 007 --LR: 6e-05 --MaxValF1: 0.8943036 --CurValF1: 0.8943036 --Patience: 01 --F1 improved: 0.8943036\n",
      "Epoch: 008 --LR: 6e-05 --MaxValF1: 0.8955622 --CurValF1: 0.8955622 --Patience: 01 --F1 improved: 0.8955622\n",
      "Epoch: 009 --LR: 6e-05 --MaxValF1: 0.8957503 --CurValF1: 0.8957503 --Patience: 01 --F1 improved: 0.8957503\n",
      "Epoch: 010 --LR: 6e-05 --MaxValF1: 0.8961677 --CurValF1: 0.8961677 --Patience: 01 --F1 improved: 0.8961677\n",
      "Epoch: 011 --LR: 6e-05 --MaxValF1: 0.8988689 --CurValF1: 0.8988689 --Patience: 01 --F1 improved: 0.8988689\n",
      "Epoch: 012 --LR: 6e-05 --MaxValF1: 0.8988689 --CurValF1: 0.8979187 --Patience: 01\n",
      "Epoch: 013 --LR: 2e-05 --MaxValF1: 0.9045726 --CurValF1: 0.9045726 --Patience: 02 --F1 improved: 0.9045726\n",
      "Epoch: 014 --LR: 2e-05 --MaxValF1: 0.9045726 --CurValF1: 0.9041639 --Patience: 01\n",
      "Epoch: 015 --LR: 5e-06 --MaxValF1: 0.9045726 --CurValF1: 0.9033113 --Patience: 02\n",
      "Epoch: 016 --LR: 2e-06 --MaxValF1: 0.9045726 --CurValF1: 0.9033977 --Patience: 03\n",
      "Epoch: 017 --LR: 5e-07 --MaxValF1: 0.9045726 --CurValF1: 0.9032043 --Patience: 04\n",
      "Training stopped due to the patience parameter. --Patience: 04\n",
      "Fold: 04 out of 05 completed.\n",
      "Local System Time: 11:15 AM\n",
      "Epoch: 001 --LR: 6e-05 --MaxValF1: 0.6453804 --CurValF1: 0.6453804 --Patience: 01 --F1 improved: 0.6453804\n",
      "Epoch: 002 --LR: 6e-05 --MaxValF1: 0.7143370 --CurValF1: 0.7143370 --Patience: 01 --F1 improved: 0.7143370\n",
      "Epoch: 003 --LR: 6e-05 --MaxValF1: 0.7932227 --CurValF1: 0.7932227 --Patience: 01 --F1 improved: 0.7932227\n",
      "Epoch: 004 --LR: 6e-05 --MaxValF1: 0.8381824 --CurValF1: 0.8381824 --Patience: 01 --F1 improved: 0.8381824\n",
      "Epoch: 005 --LR: 6e-05 --MaxValF1: 0.8544664 --CurValF1: 0.8544664 --Patience: 01 --F1 improved: 0.8544664\n",
      "Epoch: 006 --LR: 6e-05 --MaxValF1: 0.8557389 --CurValF1: 0.8557389 --Patience: 01 --F1 improved: 0.8557389\n",
      "Epoch: 007 --LR: 6e-05 --MaxValF1: 0.8637760 --CurValF1: 0.8637760 --Patience: 01 --F1 improved: 0.8637760\n",
      "Epoch: 008 --LR: 6e-05 --MaxValF1: 0.8741497 --CurValF1: 0.8741497 --Patience: 01 --F1 improved: 0.8741497\n",
      "Epoch: 009 --LR: 6e-05 --MaxValF1: 0.8813559 --CurValF1: 0.8813559 --Patience: 01 --F1 improved: 0.8813559\n",
      "Epoch: 010 --LR: 6e-05 --MaxValF1: 0.8831776 --CurValF1: 0.8831776 --Patience: 01 --F1 improved: 0.8831776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 011 --LR: 6e-05 --MaxValF1: 0.8896435 --CurValF1: 0.8896435 --Patience: 01 --F1 improved: 0.8896435\n",
      "Epoch: 012 --LR: 6e-05 --MaxValF1: 0.8919189 --CurValF1: 0.8919189 --Patience: 01 --F1 improved: 0.8919189\n",
      "Epoch: 013 --LR: 6e-05 --MaxValF1: 0.8919189 --CurValF1: 0.8894772 --Patience: 01\n",
      "Epoch: 014 --LR: 2e-05 --MaxValF1: 0.8955026 --CurValF1: 0.8955026 --Patience: 02 --F1 improved: 0.8955026\n",
      "Epoch: 015 --LR: 2e-05 --MaxValF1: 0.8955026 --CurValF1: 0.8939597 --Patience: 01\n",
      "Epoch: 016 --LR: 5e-06 --MaxValF1: 0.8955026 --CurValF1: 0.8936312 --Patience: 02\n",
      "Epoch: 017 --LR: 2e-06 --MaxValF1: 0.8955026 --CurValF1: 0.8938585 --Patience: 03\n",
      "Epoch: 018 --LR: 5e-07 --MaxValF1: 0.8955026 --CurValF1: 0.8944556 --Patience: 04\n",
      "Training stopped due to the patience parameter. --Patience: 04\n",
      "Fold: 05 out of 05 completed.\n",
      "Local System Time: 02:24 PM\n",
      "Total runtime: 14 hrs 51 mins 24.04 secs\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings( 'ignore' )\n",
    "start_time = time.time()\n",
    "print( 'Local System Time: {}'.format( time.strftime( \"%I:%M %p\", time.localtime() ) ) )\n",
    "\n",
    "valaccuracy, valprecision, valrecall, valf1, valcm = [], [], [], [], []\n",
    "testaccuracy, testprecision, testrecall, testf1, testcm = [], [], [], [], []\n",
    "com_text, com_label, com_predicted, com_prob = [], [], [], []\n",
    "com_indices = []\n",
    "hist = {}\n",
    "\n",
    "fold = 1\n",
    "for train_index, test_index in skf.split( df[ xcolumn ], df[ ycolumn ] ):\n",
    "    # seprating train and test sets\n",
    "    xtrain = df.loc[ train_index ][ xcolumn ].values\n",
    "    xtest = df.loc[ test_index ][ xcolumn ].values\n",
    "    \n",
    "    ytrain = df.loc[ train_index ][ ycolumn ].values\n",
    "    ytest = df.loc[ test_index ][ ycolumn ].values\n",
    "    \n",
    "    # splitting train and validation sets\n",
    "    xtrain, xval, ytrain, yval = train_test_split( xtrain, ytrain, test_size=0.15, random_state=0 )\n",
    "    \n",
    "    xtrain_input_ids, xtrain_attention_masks = get_tokens_and_masks(\n",
    "        BERT_TOKENIZER, xtrain.tolist(), max_length=MAX_LEN, padding='max_length'\n",
    "    )\n",
    "    \n",
    "    xval_input_ids, xval_attention_masks = get_tokens_and_masks(\n",
    "        BERT_TOKENIZER, xval.tolist(), max_length=MAX_LEN, padding='max_length'\n",
    "    )\n",
    "    \n",
    "    xtest_input_ids, xtest_attention_masks = get_tokens_and_masks(\n",
    "        BERT_TOKENIZER, xtest.tolist(), max_length=MAX_LEN, padding='max_length'\n",
    "    )\n",
    "    \n",
    "    # instantiate bert model\n",
    "    BERT_MODEL = TFMT5EncoderModel.from_pretrained( bertmodelname, config=BERT_CONFIG, cache_dir=hfcachedir )\n",
    "    BERT_MODEL.trainable = BERT_TRAINABLE\n",
    "    \n",
    "    # define a model\n",
    "    model = FineTuneBertWithDenseLayer(\n",
    "        bert_model=BERT_MODEL,\n",
    "        max_len=MAX_LEN, drpt=DRPT, fc_weights_init=FC_WEIGHTS_INIT, fc_act=FC_ACT, optimizer=OPTIMIZER\n",
    "    )\n",
    "    \n",
    "    # save model summaries and model architecture diagrams in the first fold only\n",
    "    if fold == 1:\n",
    "        plot_model( model=model, to_file='{}/{}.png'.format( modelsummaries, modelname ), show_shapes=False )\n",
    "        \n",
    "        with open( '{}/{}.txt'.format( modelsummaries, modelname ), 'w' ) as s:\n",
    "            with redirect_stdout( s ):\n",
    "                model.summary()\n",
    "    \n",
    "    K.set_value( model.optimizer.lr, LR_RATE )\n",
    "    \n",
    "    # train the model with callbacks for early stopping\n",
    "    f1callback = UT_Utils.F1_score_callback_HF(\n",
    "        val_data=( xval_input_ids, xval_attention_masks, yval ),\n",
    "        filepath=modelpath + modelname + str( fold ), patience=PATIENCE,\n",
    "        decay=DECAY, decay_rate=DECAY_RATE, decay_after=DECAY_AFTER\n",
    "    )\n",
    "    histmodel = model.fit(\n",
    "        [ xtrain_input_ids, xtrain_attention_masks ], ytrain,\n",
    "        batch_size=BATCH, epochs=NEPOCHS, verbose=0, callbacks=[ f1callback ]\n",
    "    )\n",
    "    \n",
    "    # save history of all folds\n",
    "    hist[ 'fold' + str( fold ) ] = histmodel.history.copy()\n",
    "    \n",
    "    hffinetuned = './Embeddings/hf_finetuned/{}-fold{}/'.format( bertmodelname, fold )\n",
    "    BERT_MODEL.save_pretrained( hffinetuned )\n",
    "    \n",
    "    # delete trained model object\n",
    "    del model, histmodel, f1callback, BERT_MODEL\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    # load saved model\n",
    "    FINETUNED_BERT_MODEL = TFMT5EncoderModel.from_pretrained( hffinetuned, config=BERT_CONFIG, cache_dir=hfcachedir )\n",
    "    FINETUNED_BERT_MODEL.trainable = False\n",
    "    loaded_model = load_model(\n",
    "        modelpath + modelname + str( fold ),\n",
    "        custom_objects={ 'TFMT5EncoderModel': FINETUNED_BERT_MODEL }\n",
    "    )\n",
    "    \n",
    "    # get predictions (probabilities) for validation and test sets respectively\n",
    "    valpredictions = loaded_model.predict(\n",
    "        [ xval_input_ids, xval_attention_masks ], verbose=0, batch_size=BATCH\n",
    "    )\n",
    "    testpredictions = loaded_model.predict(\n",
    "        [ xtest_input_ids, xtest_attention_masks ], verbose=0, batch_size=BATCH\n",
    "    )\n",
    "    \n",
    "    # delete loaded model\n",
    "    del loaded_model, FINETUNED_BERT_MODEL\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    # optimizer threshold on validation set\n",
    "    threshold = UT_Utils.optimize_threshold( yval, valpredictions )\n",
    "    \n",
    "    # save accuracy, precision, recall, f1 and confusion matrices\n",
    "    vallabels = ( valpredictions >= threshold ).astype( 'int32' )\n",
    "    testlabels = ( testpredictions >= threshold ).astype( 'int32' )\n",
    "    \n",
    "    valaccuracy.append( accuracy_score( yval, vallabels ) )\n",
    "    valprecision.append( precision_score( yval, vallabels ) )\n",
    "    valrecall.append( recall_score( yval, vallabels ) )\n",
    "    valf1.append( f1_score( yval, vallabels ) )\n",
    "    valcm.append( confusion_matrix( yval, vallabels ) )    \n",
    "    \n",
    "    testaccuracy.append( accuracy_score( ytest, testlabels ) )\n",
    "    testprecision.append( precision_score( ytest, testlabels ) )\n",
    "    testrecall.append( recall_score( ytest, testlabels ) )\n",
    "    testf1.append( f1_score( ytest, testlabels ) )\n",
    "    testcm.append( confusion_matrix( ytest, testlabels ) )\n",
    "    \n",
    "    # save for future analysis and ensemble\n",
    "    com_indices.extend( test_index.tolist() )\n",
    "    com_text.extend( df.loc[ test_index ][ xcolumn ] )\n",
    "    com_label.extend( df.loc[ test_index ][ ycolumn ].tolist() )\n",
    "    com_predicted.extend( testlabels[:,0].tolist() )\n",
    "    com_prob.extend( testpredictions[:,0].tolist() )\n",
    "    \n",
    "    print( 'Fold: {:02d} out of {:02d} completed.'.format( fold, skf.get_n_splits() ) )\n",
    "    print( 'Local System Time: {}'.format( time.strftime( \"%I:%M %p\", time.localtime() ) ) )\n",
    "    \n",
    "    fold = fold + 1\n",
    "time_took = time.time() - start_time\n",
    "print( f\"Total runtime: { hms_string( time_took ) }\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy\n",
      "['0.9658', '0.9662', '0.9655', '0.9670', '0.9638'] 0.9656704454368488 +- 0.0010579465899416979 \n",
      "\n",
      "Validation Precision\n",
      "['0.9204', '0.9174', '0.9182', '0.9229', '0.9118'] 0.9181612950435041 +- 0.0037115679456559696 \n",
      "\n",
      "Validation Recall\n",
      "['0.8814', '0.8882', '0.8830', '0.8869', '0.8798'] 0.8838889841324267 +- 0.0032175877327522656 \n",
      "\n",
      "Validation F1\n",
      "['0.9005', '0.9026', '0.9003', '0.9046', '0.8955'] 0.900696122323612 +- 0.0030282651919723734\n"
     ]
    }
   ],
   "source": [
    "print( 'Validation Accuracy' )\n",
    "print( [ '{:0.4f}'.format( x ) for x in valaccuracy ], np.mean( valaccuracy ), '+-', np.std( valaccuracy ), '\\n' )\n",
    "\n",
    "print( 'Validation Precision' )\n",
    "print( [ '{:0.4f}'.format( x ) for x in valprecision ], np.mean( valprecision ), '+-', np.std( valprecision ), '\\n' )\n",
    "\n",
    "print( 'Validation Recall' )\n",
    "print( [ '{:0.4f}'.format( x ) for x in valrecall ], np.mean( valrecall ), '+-', np.std( valrecall ), '\\n' )\n",
    "\n",
    "print( 'Validation F1' )\n",
    "print( [ '{:0.4f}'.format( x ) for x in valf1 ], np.mean( valf1 ), '+-', np.std( valf1 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1353  182]\n",
      " [ 117 7081]] \n",
      "\n",
      "[[1367  172]\n",
      " [ 123 7071]] \n",
      "\n",
      "[[1359  180]\n",
      " [ 121 7073]] \n",
      "\n",
      "[[1365  174]\n",
      " [ 114 7080]] \n",
      "\n",
      "[[1354  185]\n",
      " [ 131 7063]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in valcm:\n",
    "    print( np.rot90(np.rot90(c)), '\\n' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy\n",
      "['0.9642', '0.9643', '0.9649', '0.9646', '0.9607'] 0.9637492894772484 +- 0.0015436513351136962 \n",
      "\n",
      "Test Precision\n",
      "['0.9275', '0.9073', '0.9173', '0.9198', '0.9076'] 0.9158965700762352 +- 0.007664175002954552 \n",
      "\n",
      "Test Recall\n",
      "['0.8691', '0.8931', '0.8847', '0.8801', '0.8702'] 0.8794377843649899 +- 0.009037805249388955 \n",
      "\n",
      "Test F1\n",
      "['0.8973', '0.9002', '0.9007', '0.8995', '0.8885'] 0.8972409008526521 +- 0.0045169921986704855\n"
     ]
    }
   ],
   "source": [
    "print( 'Test Accuracy' )\n",
    "print( [ '{:0.4f}'.format( x ) for x in testaccuracy ], np.mean( testaccuracy ), '+-', np.std( testaccuracy ), '\\n' )\n",
    "\n",
    "print( 'Test Precision' )\n",
    "print( [ '{:0.4f}'.format( x ) for x in testprecision ], np.mean( testprecision ), '+-', np.std( testprecision ), '\\n' )\n",
    "\n",
    "print( 'Test Recall' )\n",
    "print( [ '{:0.4f}'.format( x ) for x in testrecall ], np.mean( testrecall ), '+-', np.std( testrecall ), '\\n' )\n",
    "\n",
    "print( 'Test F1' )\n",
    "print( [ '{:0.4f}'.format( x ) for x in testf1 ], np.mean( testf1 ), '+-', np.std( testf1 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2277   343]\n",
      " [  178 11757]] \n",
      "\n",
      "[[ 2340   280]\n",
      " [  239 11695]] \n",
      "\n",
      "[[ 2317   302]\n",
      " [  209 11726]] \n",
      "\n",
      "[[ 2305   314]\n",
      " [  201 11734]] \n",
      "\n",
      "[[ 2279   340]\n",
      " [  232 11703]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in testcm:\n",
    "    print( np.rot90(np.rot90(c)), '\\n' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open( '{}/ResultsMain.csv'.format( modelresults ), mode='a' )\n",
    "file.write( modelname )\n",
    "file.write( ',' )\n",
    "file.write( str(np.mean( testaccuracy ))[:7] + '+-' + str(np.std( testaccuracy ))[:6] )\n",
    "file.write( ',' )\n",
    "file.write( str(np.mean( testprecision ))[:7] + '+-' + str(np.std( testprecision ))[:6] )\n",
    "file.write( ',' )\n",
    "file.write( str(np.mean( testrecall ))[:7] + '+-' + str(np.std( testrecall ))[:6] )\n",
    "file.write( ',' )\n",
    "file.write( str(np.mean( testf1 ))[:7] + '+-' + str(np.std( testf1 ))[:6] )\n",
    "file.write( '\\n' )\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72771, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPredictions = pd.DataFrame(  )\n",
    "dfPredictions[ 'comment_indices' ] = com_indices\n",
    "#dfPredictions[ 'comment_text' ] = com_text #comment text\n",
    "dfPredictions[ 'comment_label' ] = com_label\n",
    "dfPredictions[ 'comment_predicted' ] = com_predicted\n",
    "dfPredictions[ 'comment_prob' ] = com_prob\n",
    "dfPredictions.to_csv( '{}/{}.csv'.format( modelresults, modelname ), index=False )\n",
    "dfPredictions.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_2.8",
   "language": "python",
   "name": "tf_2.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
